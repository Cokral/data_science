{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to explore the basics of Pytorch, the deep learning pytonic library.  \n",
    "The goal is to learn how to use it to implement complex deep learning models to use them in various projects and competitions.\n",
    "\n",
    "This notebook corresponds to following the videos of sentdex from Youtube on Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Torch Operations\n",
    "\n",
    "Torch takes a lot from numpy, the math library it is based on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  3.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([5, 3])\n",
    "y = torch.Tensor([2, 1])\n",
    "\n",
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.zeros([2, 5])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8462, 0.8048, 0.9736, 0.9234, 0.1274],\n",
       "        [0.8660, 0.3702, 0.1006, 0.2321, 0.2755]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.rand([2, 5])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8462, 0.8048, 0.9736, 0.9234, 0.1274, 0.8660, 0.3702, 0.1006, 0.2321,\n",
       "         0.2755]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape method\n",
    "w.view([1, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to play around the MNIST Dataset to understand the basics and fundamentals of data manipulation with and for pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = datasets.MNIST('',\n",
    "                       train=True,\n",
    "                       download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST('',\n",
    "                      train=False,\n",
    "                      download=True,\n",
    "                      transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([3, 9, 9, 0, 6, 3, 3, 4, 1, 7])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.imshow(data[0][0].view(28, 28));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_dict = {x:0 for x in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1 \n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5923,\n",
       " 1: 6742,\n",
       " 2: 5958,\n",
       " 3: 6131,\n",
       " 4: 5842,\n",
       " 5: 5421,\n",
       " 6: 5918,\n",
       " 7: 6265,\n",
       " 8: 5851,\n",
       " 9: 5949}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.09871666666666666\n",
      "1 : 0.11236666666666667\n",
      "2 : 0.0993\n",
      "3 : 0.10218333333333333\n",
      "4 : 0.09736666666666667\n",
      "5 : 0.09035\n",
      "6 : 0.09863333333333334\n",
      "7 : 0.10441666666666667\n",
      "8 : 0.09751666666666667\n",
      "9 : 0.09915\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f'{i} : {counter_dict[i] / total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0].numel() #28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=28*28, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=64)\n",
    "        self.fc4 = nn.Linear(in_features=64, out_features=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.view(1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3400, -2.2879, -2.1966, -2.1997, -2.3270, -2.3678, -2.2229, -2.3573,\n",
       "         -2.4373, -2.3173]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 → 0.008239984512329102\n",
      "Epoch #1 → 0.021681571379303932\n",
      "Epoch #2 → 0.0033586081117391586\n"
     ]
    }
   ],
   "source": [
    "# epoch = full pass through the data\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28 * 28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch #{epoch} → {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train_set : 0.978\n",
      "Accuracy for test_set : 0.976\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for key, dataset in {'train_set': trainset, 'test_set': testset}.items():\n",
    "        for data in dataset:\n",
    "            X, y = data\n",
    "            output = net(X.view(-1, 28 * 28))\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "        print(f'Accuracy for {key} : {round(correct/total, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[1].view(28, 28));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(net(X[1].view(-1, 28*28))[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
