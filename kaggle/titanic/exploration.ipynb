{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of the Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "gender_submission = pd.read_csv('data/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_id = test.PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, both the train and the test sets are very small (< 1000 examples with 11 features).  \n",
    "We will study them thoroughly in order to understand each feature's importance and how to use it in order to classify each passenger.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dive in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature \"Survived\" will be our target feature in that case : we just need to make sure what kind it is (binary or not). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train.Survived.value_counts() / train.shape[0]).plot.bar(color=['#854D27', '#F4C95D']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on the plot above : ~60% of the passengers are Survived = 0 and the others are Survived = 1.   \n",
    "It means that the dataset isn't imbalanced but, we could still balance it to 50/50 if we see that our classification accuracy is bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, only three features are categorical \"Name\", \"Sex\" and \"Ticket\".  \n",
    "We will need to handle them differently in order to be able to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_percent = train.nunique() / train.shape[0]\n",
    "unique_values_percent.name = 'unique_values_percent'\n",
    "\n",
    "unique_values = train.nunique()\n",
    "unique_values.name = 'unique_values'\n",
    "\n",
    "nan_percent = train.isna().sum() / train.shape[0]\n",
    "nan_percent.name = 'nan_percent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_values</th>\n",
       "      <th>unique_values_percent</th>\n",
       "      <th>nan_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PassengerId</td>\n",
       "      <td>891.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Survived</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pclass</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Name</td>\n",
       "      <td>891.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sex</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.198653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SibSp</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.007856</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Parch</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.007856</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ticket</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.764310</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fare</td>\n",
       "      <td>248.0</td>\n",
       "      <td>0.278339</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Cabin</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.164983</td>\n",
       "      <td>0.771044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Embarked</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.002245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             unique_values  unique_values_percent  nan_percent\n",
       "PassengerId          891.0               1.000000     0.000000\n",
       "Survived               2.0               0.002245     0.000000\n",
       "Pclass                 3.0               0.003367     0.000000\n",
       "Name                 891.0               1.000000     0.000000\n",
       "Sex                    2.0               0.002245     0.000000\n",
       "Age                   88.0               0.098765     0.198653\n",
       "SibSp                  7.0               0.007856     0.000000\n",
       "Parch                  7.0               0.007856     0.000000\n",
       "Ticket               681.0               0.764310     0.000000\n",
       "Fare                 248.0               0.278339     0.000000\n",
       "Cabin                147.0               0.164983     0.771044\n",
       "Embarked               3.0               0.003367     0.002245"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_information = pd.DataFrame(data=[unique_values, unique_values_percent, nan_percent]).T\n",
    "features_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above we can see various interesting and important information : \n",
    " - 2 features **PassengerId** and **Name** contain completely unique values, thus, there is no point in using them from classification as they carry no information.\n",
    " - Only 3 features contain missing values, **Cabin**, **Age** and **Embarked**. We will need to decide what we do in each case. \n",
    " - **Ticket** feature contains a lot of different values and it might not be a good idea to use this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the features \"SibSp\" and \"Parch\" combine contain the size of the family of said passenger.  \n",
    "Combining them to make a variable will be interesting for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping useless variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = train.copy().drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the feature Name seems to contain relevant information on the passenger : his status (Mrs, Ms, Mr...).  \n",
    "We are going to extract this variable and use it for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we explained it above, we are going to extract information from the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_passenger = train_cleaned.Name.apply(lambda x: x.split('.')[0].split(' ')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = train_cleaned.assign(status_passenger=status_passenger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr          517\n",
       "Miss        182\n",
       "Mrs         125\n",
       "Master       40\n",
       "Dr            7\n",
       "Rev           6\n",
       "Col           2\n",
       "Mlle          2\n",
       "Major         2\n",
       "Don           1\n",
       "Mme           1\n",
       "Ms            1\n",
       "Jonkheer      1\n",
       "Capt          1\n",
       "Sir           1\n",
       "Countess      1\n",
       "Lady          1\n",
       "Name: status_passenger, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.status_passenger.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned.status_passenger = train_cleaned.status_passenger.replace({'Mme': 'Mrs', 'Ms': 'Miss', 'Mlle': 'Miss'})\n",
    "train_cleaned.status_passenger = train_cleaned.status_passenger.replace(['Dr', 'Rev', 'Col', 'Major', 'Sir', 'Lady', 'Capt', 'Countess', 'Jonkheer', 'Don'], 'Rare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr        517\n",
       "Miss      185\n",
       "Mrs       126\n",
       "Master     40\n",
       "Rare       23\n",
       "Name: status_passenger, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.status_passenger.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focus on the variables with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C23 C25 C27    4\n",
       "G6             4\n",
       "B96 B98        4\n",
       "C22 C26        3\n",
       "F2             3\n",
       "              ..\n",
       "B41            1\n",
       "E12            1\n",
       "D50            1\n",
       "E36            1\n",
       "C104           1\n",
       "Name: Cabin, Length: 147, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Cabin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first it seems that the \"Cabin\" feature contains the cabin used by the passenger, but we have this information in only 33% of the cases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can try, is to see if the cabin information is related in anyway with the survival of the titanic.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned['has_cabin'] = False\n",
    "train_cleaned.loc[train_cleaned.Cabin.notna(), 'has_cabin'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_cabin  Survived\n",
       "False      0           481\n",
       "           1           206\n",
       "True       1           136\n",
       "           0            68\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.groupby('has_cabin').Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3169115231122959"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Survived.corr(train_cleaned.has_cabin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there seem to be some kind of correlation between the made variable \"has_cabin\" and our target feature \"Survived\".  \n",
    "We will keep it as such for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = train_cleaned.drop('Cabin', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_cleaned.Age.plot(kind='hist', bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07722109457217764"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Survived.corr(train_cleaned.Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This variable is missing for about 20% of the samples, so we are going to compute the median age for those missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_age = train_cleaned.Age.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned['Age'] = train_cleaned.Age.fillna(median_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06491041993052588"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Survived.corr(train_cleaned.Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This variable corresponds to the harbour where the passenger got on board from.  \n",
    "There are three options and a few missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, there seems to be kind of a correlation between embarking at the harbour S and surviving the incident.  \n",
    "It might be totally random though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned['embarked_s'] = False\n",
    "train_cleaned['embarked_s'] = train_cleaned.Embarked == 'S'\n",
    "\n",
    "train_cleaned['embarked_q'] = False\n",
    "train_cleaned['embarked_q'] = train_cleaned.Embarked == 'Q'\n",
    "\n",
    "train_cleaned['embarked_c'] = False\n",
    "train_cleaned['embarked_c'] = train_cleaned.Embarked == 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15566027340439317"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Survived.corr(train_cleaned.embarked_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003650382683971961"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Survived.corr(train_cleaned.embarked_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16824043121823284"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Survived.corr(train_cleaned.embarked_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here for the missing values, there is nothing we can do so we are gonna leave them missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned['sex_male'] = False\n",
    "train_cleaned['sex_male'] = train_cleaned.Sex == 'male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.543351380657755"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Survived.corr(train_cleaned.sex_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on above, there is a correlation between the sex of the passenger and his survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA. 2343           7\n",
       "1601               7\n",
       "347082             7\n",
       "3101295            6\n",
       "CA 2144            6\n",
       "                  ..\n",
       "SOTON/OQ 392090    1\n",
       "364500             1\n",
       "SC/PARIS 2133      1\n",
       "111426             1\n",
       "PC 17600           1\n",
       "Name: Ticket, Length: 681, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be too many different values, and as they occur too few times, they won't carry the necessary information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned.drop('Ticket', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>status_passenger</th>\n",
       "      <th>has_cabin</th>\n",
       "      <th>embarked_s</th>\n",
       "      <th>embarked_q</th>\n",
       "      <th>embarked_c</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch     Fare Embarked status_passenger  has_cabin  \\\n",
       "0    male  22.0      1      0   7.2500        S               Mr      False   \n",
       "1  female  38.0      1      0  71.2833        C              Mrs       True   \n",
       "2  female  26.0      0      0   7.9250        S             Miss      False   \n",
       "3  female  35.0      1      0  53.1000        S              Mrs       True   \n",
       "4    male  35.0      0      0   8.0500        S               Mr      False   \n",
       "\n",
       "   embarked_s  embarked_q  embarked_c  sex_male  \n",
       "0        True       False       False      True  \n",
       "1       False       False        True     False  \n",
       "2        True       False       False     False  \n",
       "3        True       False       False     False  \n",
       "4        True       False       False      True  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.33848103596101475"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Survived.corr(train_cleaned.Pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Pclass.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could make binary variables for the class, but, as it is, there is meaning in keeping it in the numerical way.  \n",
    "As there is a true difference where 1 > 2 > 3 (or the inverse).  \n",
    "So we will keep this variable this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Family size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the family size in a feature, we simply need to add up the values of Parch, SibSp and 1 (corresponding to the passenger). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned['family_size'] = train_cleaned.SibSp + train_cleaned.Parch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     537\n",
       "2     161\n",
       "3     102\n",
       "4      29\n",
       "6      22\n",
       "5      15\n",
       "7      12\n",
       "11      7\n",
       "8       6\n",
       "Name: family_size, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.family_size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01663898928274532"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Survived.corr(train_cleaned.family_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be little to no correlation between this and our target variable Survived.  \n",
    "Instead, we could use this to express if the passenger is alone or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned['is_alone'] = train_cleaned.family_size == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.20336708569989215"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.Survived.corr(train_cleaned.is_alone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we can see this variable contains much more interesting information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last cleaning touches + applying to the test set\n",
    "\n",
    "Now that we covered every feature and how they're gonna be used for modeling, we can go ahead and encode them in a way for models to work with them, i.e. numerical variables instead of categorical variables.\n",
    "\n",
    "There exists various ways of encoding variables : target encoding, one-hot encoding, integer encoding...  \n",
    "In our case, and because we don't have too many cases for each feature to encode, we will stick to one-hot encoding which consists on making new binary features for each possible value of a categorical feature.  \n",
    "For example : the feature containing the title of the passenger will become title_mr, title_mlle, title_mrs, etc.  And each new feature is a binary feature containing either a 0 or a 1.  \n",
    "\n",
    "Thanks to this encoding, we don't lose any information from the variable and allow it to be used in various statistical models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish cleaning training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>status_passenger</th>\n",
       "      <th>has_cabin</th>\n",
       "      <th>embarked_s</th>\n",
       "      <th>embarked_q</th>\n",
       "      <th>embarked_c</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                     Name   Sex   Age  SibSp  Parch  Fare  \\\n",
       "0         0       3  Braund, Mr. Owen Harris  male  22.0      1      0  7.25   \n",
       "\n",
       "  Embarked status_passenger  has_cabin  embarked_s  embarked_q  embarked_c  \\\n",
       "0        S               Mr      False        True       False       False   \n",
       "\n",
       "   sex_male  family_size  is_alone  \n",
       "0      True            2     False  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we already did part of the job for **embarked** and **sex**.  \n",
    "\n",
    "We need to also do the work for our newly made variable **status_passenger**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = train_cleaned.join(pd.get_dummies(train_cleaned['status_passenger']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
       "       'Embarked', 'status_passenger', 'has_cabin', 'embarked_s', 'embarked_q',\n",
       "       'embarked_c', 'sex_male', 'family_size', 'is_alone', 'Master', 'Miss',\n",
       "       'Mr', 'Mrs', 'Rare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['Name', 'Sex', 'SibSp', 'Parch', 'Embarked', 'status_passenger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = train_cleaned.drop(features_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = train_cleaned.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['has_cabin'] = False\n",
    "test['has_cabin'] = test.Cabin.notna()\n",
    "\n",
    "test['embarked_s'] = False\n",
    "test['embarked_s'] = test.Embarked == 'S'\n",
    "\n",
    "test['embarked_q'] = False\n",
    "test['embarked_q'] = test.Embarked == 'Q'\n",
    "\n",
    "test['embarked_c'] = False\n",
    "test['embarked_c'] = test.Embarked == 'C'\n",
    "\n",
    "test['Age'].fillna(test.Age.median(), inplace=True)\n",
    "\n",
    "test['sex_male'] = False\n",
    "test['sex_male'] = test.Sex == 'male'\n",
    "\n",
    "test['family_size'] = test.SibSp + test .Parch + 1\n",
    "\n",
    "test['is_alone'] = test.family_size == 1\n",
    "\n",
    "test_status_passenger = test.Name.apply(lambda x: x.split('.')[0].split(' ')[-1])\n",
    "test = test.assign(status_passenger=test_status_passenger)\n",
    "test.status_passenger = test.status_passenger.replace({'Mme': 'Mrs', 'Ms': 'Miss', 'Mlle': 'Miss'})\n",
    "test.status_passenger = test.status_passenger.replace(['Dona', 'Dr', 'Rev', 'Col', 'Major', 'Sir', 'Lady', 'Capt', 'Countess', 'Jonkheer', 'Don'], 'Rare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.join(pd.get_dummies(test.status_passenger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(features_to_drop, axis=1)\n",
    "test = test.drop(['PassengerId', 'Ticket', 'Cabin'], axis=1)\n",
    "test.replace({True: 1, False: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>has_cabin</th>\n",
       "      <th>embarked_s</th>\n",
       "      <th>embarked_q</th>\n",
       "      <th>embarked_c</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>Master</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Rare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age     Fare  has_cabin  embarked_s  embarked_q  embarked_c  \\\n",
       "0       3  34.5   7.8292          0           0           1           0   \n",
       "1       3  47.0   7.0000          0           1           0           0   \n",
       "2       2  62.0   9.6875          0           0           1           0   \n",
       "3       3  27.0   8.6625          0           1           0           0   \n",
       "4       3  22.0  12.2875          0           1           0           0   \n",
       "\n",
       "   sex_male  family_size  is_alone  Master  Miss  Mr  Mrs  Rare  \n",
       "0         1            1         1       0     0   1    0     0  \n",
       "1         0            2         0       0     0   0    1     0  \n",
       "2         1            1         1       0     0   1    0     0  \n",
       "3         1            1         1       0     0   1    0     0  \n",
       "4         0            3         0       0     0   0    1     0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_cleaned['Survived']\n",
    "X = train_cleaned.drop(['Survived'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.copy()\n",
    "X_test.Fare.fillna(X_test.Fare.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try a lot of different models.  \n",
    "For this kind of exercise (a one-time contest), an ensembling method can be a good solution.  \n",
    "Combining a lot of different models after tunning them.  \n",
    "\n",
    "In the case of a production ML model, it will be better to stay on a **simpler** and more **understandable** model (occam's razor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (\n",
    "    ensemble,\n",
    "    gaussian_process,\n",
    "    linear_model,\n",
    "    naive_bayes,\n",
    "    neighbors,\n",
    "    svm,\n",
    "    tree,\n",
    "    discriminant_analysis\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_algorithms = [\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(n_estimators=100),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(n_estimators=100),\n",
    "\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "     \n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna compare a lot of different models available.  \n",
    "The idea will be to combine them with an ensembling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_split = ShuffleSplit(n_splits=3, test_size=.2, train_size=.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_columns = ['Model Name', 'Model Parameters', 'Model Train F1 Score Mean', 'Model Test F1 Score Mean', 'Model Test F1 Score 3*STD' ,'Model Time']\n",
    "results = pd.DataFrame(columns = results_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> AdaBoostClassifier\n",
      "> BaggingClassifier\n",
      "> ExtraTreesClassifier\n",
      "> GradientBoostingClassifier\n",
      "> RandomForestClassifier\n",
      "> GaussianProcessClassifier\n",
      "> PassiveAggressiveClassifier\n",
      "> RidgeClassifierCV\n",
      "> SGDClassifier\n",
      "> Perceptron\n",
      "> BernoulliNB\n",
      "> GaussianNB\n",
      "> KNeighborsClassifier\n",
      "> SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> NuSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> LinearSVC\n",
      "> DecisionTreeClassifier\n",
      "> ExtraTreeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> LinearDiscriminantAnalysis\n",
      "> QuadraticDiscriminantAnalysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Parameters</th>\n",
       "      <th>Model Train F1 Score Mean</th>\n",
       "      <th>Model Test F1 Score Mean</th>\n",
       "      <th>Model Test F1 Score 3*STD</th>\n",
       "      <th>Model Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.801093</td>\n",
       "      <td>0.752075</td>\n",
       "      <td>0.0609638</td>\n",
       "      <td>0.0706893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'n_components': None, 'priors': None, 'shrink...</td>\n",
       "      <td>0.783491</td>\n",
       "      <td>0.75198</td>\n",
       "      <td>0.0889854</td>\n",
       "      <td>0.00699608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n",
       "      <td>0.875574</td>\n",
       "      <td>0.751254</td>\n",
       "      <td>0.069696</td>\n",
       "      <td>0.0796671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.748159</td>\n",
       "      <td>0.076795</td>\n",
       "      <td>0.00633303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.956077</td>\n",
       "      <td>0.725697</td>\n",
       "      <td>0.0916368</td>\n",
       "      <td>0.017988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'cri...</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.721341</td>\n",
       "      <td>0.0911531</td>\n",
       "      <td>0.122347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>0.740125</td>\n",
       "      <td>0.712698</td>\n",
       "      <td>0.0992032</td>\n",
       "      <td>0.00266623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.748321</td>\n",
       "      <td>0.702294</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.00266711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'cr...</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.700279</td>\n",
       "      <td>0.152178</td>\n",
       "      <td>0.104001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.698069</td>\n",
       "      <td>0.0609913</td>\n",
       "      <td>0.00266631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.641118</td>\n",
       "      <td>0.099632</td>\n",
       "      <td>0.0026656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.749129</td>\n",
       "      <td>0.625394</td>\n",
       "      <td>0.0653938</td>\n",
       "      <td>0.0030009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'cache_size': 200, 'class_weight': None, 'coe...</td>\n",
       "      <td>0.88062</td>\n",
       "      <td>0.62482</td>\n",
       "      <td>0.135416</td>\n",
       "      <td>0.0906599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'cache_size': 200, 'class_weight': ...</td>\n",
       "      <td>0.851942</td>\n",
       "      <td>0.609723</td>\n",
       "      <td>0.0642592</td>\n",
       "      <td>0.0869946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
       "      <td>0.941706</td>\n",
       "      <td>0.576224</td>\n",
       "      <td>0.026924</td>\n",
       "      <td>0.320696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>0.53418</td>\n",
       "      <td>0.51046</td>\n",
       "      <td>0.750526</td>\n",
       "      <td>0.00433413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.579064</td>\n",
       "      <td>0.505241</td>\n",
       "      <td>0.400666</td>\n",
       "      <td>0.0353279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "      <td>0.424493</td>\n",
       "      <td>0.456111</td>\n",
       "      <td>0.722615</td>\n",
       "      <td>0.0036664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
       "      <td>0.24482</td>\n",
       "      <td>0.207733</td>\n",
       "      <td>0.297017</td>\n",
       "      <td>0.00333095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
       "      <td>0.0567638</td>\n",
       "      <td>0.0369634</td>\n",
       "      <td>0.0347295</td>\n",
       "      <td>0.00266616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model Name  \\\n",
       "0              AdaBoostClassifier   \n",
       "18     LinearDiscriminantAnalysis   \n",
       "3      GradientBoostingClassifier   \n",
       "7               RidgeClassifierCV   \n",
       "1               BaggingClassifier   \n",
       "4          RandomForestClassifier   \n",
       "10                    BernoulliNB   \n",
       "11                     GaussianNB   \n",
       "2            ExtraTreesClassifier   \n",
       "16         DecisionTreeClassifier   \n",
       "17            ExtraTreeClassifier   \n",
       "12           KNeighborsClassifier   \n",
       "14                          NuSVC   \n",
       "13                            SVC   \n",
       "5       GaussianProcessClassifier   \n",
       "8                   SGDClassifier   \n",
       "15                      LinearSVC   \n",
       "9                      Perceptron   \n",
       "6     PassiveAggressiveClassifier   \n",
       "19  QuadraticDiscriminantAnalysis   \n",
       "\n",
       "                                     Model Parameters  \\\n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...   \n",
       "18  {'n_components': None, 'priors': None, 'shrink...   \n",
       "3   {'criterion': 'friedman_mse', 'init': None, 'l...   \n",
       "7   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...   \n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...   \n",
       "4   {'bootstrap': True, 'class_weight': None, 'cri...   \n",
       "10  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...   \n",
       "11           {'priors': None, 'var_smoothing': 1e-09}   \n",
       "2   {'bootstrap': False, 'class_weight': None, 'cr...   \n",
       "16  {'class_weight': None, 'criterion': 'gini', 'm...   \n",
       "17  {'class_weight': None, 'criterion': 'gini', 'm...   \n",
       "12  {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "14  {'cache_size': 200, 'class_weight': None, 'coe...   \n",
       "13  {'C': 1.0, 'cache_size': 200, 'class_weight': ...   \n",
       "5   {'copy_X_train': True, 'kernel': None, 'max_it...   \n",
       "8   {'alpha': 0.0001, 'average': False, 'class_wei...   \n",
       "15  {'C': 1.0, 'class_weight': None, 'dual': True,...   \n",
       "9   {'alpha': 0.0001, 'class_weight': None, 'early...   \n",
       "6   {'C': 1.0, 'average': False, 'class_weight': N...   \n",
       "19  {'priors': None, 'reg_param': 0.0, 'store_cova...   \n",
       "\n",
       "   Model Train F1 Score Mean Model Test F1 Score Mean  \\\n",
       "0                   0.801093                 0.752075   \n",
       "18                  0.783491                  0.75198   \n",
       "3                   0.875574                 0.751254   \n",
       "7                      0.787                 0.748159   \n",
       "1                   0.956077                 0.725697   \n",
       "4                   0.983239                 0.721341   \n",
       "10                  0.740125                 0.712698   \n",
       "11                  0.748321                 0.702294   \n",
       "2                   0.983239                 0.700279   \n",
       "16                  0.983239                 0.698069   \n",
       "17                  0.983239                 0.641118   \n",
       "12                  0.749129                 0.625394   \n",
       "14                   0.88062                  0.62482   \n",
       "13                  0.851942                 0.609723   \n",
       "5                   0.941706                 0.576224   \n",
       "8                    0.53418                  0.51046   \n",
       "15                  0.579064                 0.505241   \n",
       "9                   0.424493                 0.456111   \n",
       "6                    0.24482                 0.207733   \n",
       "19                 0.0567638                0.0369634   \n",
       "\n",
       "   Model Test F1 Score 3*STD  Model Time  \n",
       "0                  0.0609638   0.0706893  \n",
       "18                 0.0889854  0.00699608  \n",
       "3                   0.069696   0.0796671  \n",
       "7                   0.076795  0.00633303  \n",
       "1                  0.0916368    0.017988  \n",
       "4                  0.0911531    0.122347  \n",
       "10                 0.0992032  0.00266623  \n",
       "11                    0.1186  0.00266711  \n",
       "2                   0.152178    0.104001  \n",
       "16                 0.0609913  0.00266631  \n",
       "17                  0.099632   0.0026656  \n",
       "12                 0.0653938   0.0030009  \n",
       "14                  0.135416   0.0906599  \n",
       "13                 0.0642592   0.0869946  \n",
       "5                   0.026924    0.320696  \n",
       "8                   0.750526  0.00433413  \n",
       "15                  0.400666   0.0353279  \n",
       "9                   0.722615   0.0036664  \n",
       "6                   0.297017  0.00333095  \n",
       "19                 0.0347295  0.00266616  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_index = 0\n",
    "model_predictions = {}\n",
    "for model in ml_algorithms:\n",
    "    model_name = model.__class__.__name__\n",
    "    print(f'> {model_name}')\n",
    "    results.loc[row_index, 'Model Name'] = model_name\n",
    "    results.loc[row_index, 'Model Parameters'] = str(model.get_params())\n",
    "    \n",
    "    cv_results = cross_validate(model, X, y, cv=cv_split, scoring='f1', return_train_score=True)\n",
    "\n",
    "    results.loc[row_index, 'Model Time'] = cv_results['fit_time'].mean()\n",
    "    results.loc[row_index, 'Model Train F1 Score Mean'] = cv_results['train_score'].mean()\n",
    "    results.loc[row_index, 'Model Test F1 Score Mean'] = cv_results['test_score'].mean()   \n",
    "    results.loc[row_index, 'Model Test F1 Score 3*STD'] = cv_results['test_score'].std() * 3 \n",
    "\n",
    "    model.fit(X, y)\n",
    "    model_predictions[model_name] = model.predict(X)\n",
    "    \n",
    "    row_index+=1\n",
    "  \n",
    "results.sort_values(by=['Model Test F1 Score Mean'], ascending=False, inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Parameters</th>\n",
       "      <th>Model Train F1 Score Mean</th>\n",
       "      <th>Model Test F1 Score Mean</th>\n",
       "      <th>Model Test F1 Score 3*STD</th>\n",
       "      <th>Model Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.801093</td>\n",
       "      <td>0.752075</td>\n",
       "      <td>0.0609638</td>\n",
       "      <td>0.0706893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'n_components': None, 'priors': None, 'shrink...</td>\n",
       "      <td>0.783491</td>\n",
       "      <td>0.75198</td>\n",
       "      <td>0.0889854</td>\n",
       "      <td>0.00699608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n",
       "      <td>0.875574</td>\n",
       "      <td>0.751254</td>\n",
       "      <td>0.069696</td>\n",
       "      <td>0.0796671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.748159</td>\n",
       "      <td>0.076795</td>\n",
       "      <td>0.00633303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.956077</td>\n",
       "      <td>0.725697</td>\n",
       "      <td>0.0916368</td>\n",
       "      <td>0.017988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'cri...</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.721341</td>\n",
       "      <td>0.0911531</td>\n",
       "      <td>0.122347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>0.740125</td>\n",
       "      <td>0.712698</td>\n",
       "      <td>0.0992032</td>\n",
       "      <td>0.00266623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.748321</td>\n",
       "      <td>0.702294</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.00266711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'cr...</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.700279</td>\n",
       "      <td>0.152178</td>\n",
       "      <td>0.104001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.698069</td>\n",
       "      <td>0.0609913</td>\n",
       "      <td>0.00266631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.641118</td>\n",
       "      <td>0.099632</td>\n",
       "      <td>0.0026656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.749129</td>\n",
       "      <td>0.625394</td>\n",
       "      <td>0.0653938</td>\n",
       "      <td>0.0030009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'cache_size': 200, 'class_weight': None, 'coe...</td>\n",
       "      <td>0.88062</td>\n",
       "      <td>0.62482</td>\n",
       "      <td>0.135416</td>\n",
       "      <td>0.0906599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'cache_size': 200, 'class_weight': ...</td>\n",
       "      <td>0.851942</td>\n",
       "      <td>0.609723</td>\n",
       "      <td>0.0642592</td>\n",
       "      <td>0.0869946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
       "      <td>0.941706</td>\n",
       "      <td>0.576224</td>\n",
       "      <td>0.026924</td>\n",
       "      <td>0.320696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>0.53418</td>\n",
       "      <td>0.51046</td>\n",
       "      <td>0.750526</td>\n",
       "      <td>0.00433413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.579064</td>\n",
       "      <td>0.505241</td>\n",
       "      <td>0.400666</td>\n",
       "      <td>0.0353279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "      <td>0.424493</td>\n",
       "      <td>0.456111</td>\n",
       "      <td>0.722615</td>\n",
       "      <td>0.0036664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
       "      <td>0.24482</td>\n",
       "      <td>0.207733</td>\n",
       "      <td>0.297017</td>\n",
       "      <td>0.00333095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
       "      <td>0.0567638</td>\n",
       "      <td>0.0369634</td>\n",
       "      <td>0.0347295</td>\n",
       "      <td>0.00266616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model Name  \\\n",
       "0              AdaBoostClassifier   \n",
       "18     LinearDiscriminantAnalysis   \n",
       "3      GradientBoostingClassifier   \n",
       "7               RidgeClassifierCV   \n",
       "1               BaggingClassifier   \n",
       "4          RandomForestClassifier   \n",
       "10                    BernoulliNB   \n",
       "11                     GaussianNB   \n",
       "2            ExtraTreesClassifier   \n",
       "16         DecisionTreeClassifier   \n",
       "17            ExtraTreeClassifier   \n",
       "12           KNeighborsClassifier   \n",
       "14                          NuSVC   \n",
       "13                            SVC   \n",
       "5       GaussianProcessClassifier   \n",
       "8                   SGDClassifier   \n",
       "15                      LinearSVC   \n",
       "9                      Perceptron   \n",
       "6     PassiveAggressiveClassifier   \n",
       "19  QuadraticDiscriminantAnalysis   \n",
       "\n",
       "                                     Model Parameters  \\\n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...   \n",
       "18  {'n_components': None, 'priors': None, 'shrink...   \n",
       "3   {'criterion': 'friedman_mse', 'init': None, 'l...   \n",
       "7   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...   \n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...   \n",
       "4   {'bootstrap': True, 'class_weight': None, 'cri...   \n",
       "10  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...   \n",
       "11           {'priors': None, 'var_smoothing': 1e-09}   \n",
       "2   {'bootstrap': False, 'class_weight': None, 'cr...   \n",
       "16  {'class_weight': None, 'criterion': 'gini', 'm...   \n",
       "17  {'class_weight': None, 'criterion': 'gini', 'm...   \n",
       "12  {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "14  {'cache_size': 200, 'class_weight': None, 'coe...   \n",
       "13  {'C': 1.0, 'cache_size': 200, 'class_weight': ...   \n",
       "5   {'copy_X_train': True, 'kernel': None, 'max_it...   \n",
       "8   {'alpha': 0.0001, 'average': False, 'class_wei...   \n",
       "15  {'C': 1.0, 'class_weight': None, 'dual': True,...   \n",
       "9   {'alpha': 0.0001, 'class_weight': None, 'early...   \n",
       "6   {'C': 1.0, 'average': False, 'class_weight': N...   \n",
       "19  {'priors': None, 'reg_param': 0.0, 'store_cova...   \n",
       "\n",
       "   Model Train F1 Score Mean Model Test F1 Score Mean  \\\n",
       "0                   0.801093                 0.752075   \n",
       "18                  0.783491                  0.75198   \n",
       "3                   0.875574                 0.751254   \n",
       "7                      0.787                 0.748159   \n",
       "1                   0.956077                 0.725697   \n",
       "4                   0.983239                 0.721341   \n",
       "10                  0.740125                 0.712698   \n",
       "11                  0.748321                 0.702294   \n",
       "2                   0.983239                 0.700279   \n",
       "16                  0.983239                 0.698069   \n",
       "17                  0.983239                 0.641118   \n",
       "12                  0.749129                 0.625394   \n",
       "14                   0.88062                  0.62482   \n",
       "13                  0.851942                 0.609723   \n",
       "5                   0.941706                 0.576224   \n",
       "8                    0.53418                  0.51046   \n",
       "15                  0.579064                 0.505241   \n",
       "9                   0.424493                 0.456111   \n",
       "6                    0.24482                 0.207733   \n",
       "19                 0.0567638                0.0369634   \n",
       "\n",
       "   Model Test F1 Score 3*STD  Model Time  \n",
       "0                  0.0609638   0.0706893  \n",
       "18                 0.0889854  0.00699608  \n",
       "3                   0.069696   0.0796671  \n",
       "7                   0.076795  0.00633303  \n",
       "1                  0.0916368    0.017988  \n",
       "4                  0.0911531    0.122347  \n",
       "10                 0.0992032  0.00266623  \n",
       "11                    0.1186  0.00266711  \n",
       "2                   0.152178    0.104001  \n",
       "16                 0.0609913  0.00266631  \n",
       "17                  0.099632   0.0026656  \n",
       "12                 0.0653938   0.0030009  \n",
       "14                  0.135416   0.0906599  \n",
       "13                 0.0642592   0.0869946  \n",
       "5                   0.026924    0.320696  \n",
       "8                   0.750526  0.00433413  \n",
       "15                  0.400666   0.0353279  \n",
       "9                   0.722615   0.0036664  \n",
       "6                   0.297017  0.00333095  \n",
       "19                 0.0347295  0.00266616  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see the results of each model tested : with both their F1 scores on the training set and on the test sets.  \n",
    "A few key inputs can be gathered from just this information : \n",
    " - First, when the model **train** mean score is close to 1 (0.98...) but the **test** mean score is much smaller (0.68 ? DecisionTreeClassifier for example). It means that our model is **overfitting**. \n",
    "A few solutions exist in order to avoid overfitting : if possible, you can use **more data** to train your model, you can use a **regularization term** in the model or increase its value...\n",
    "We shouldn't be too worried as for now, we haven't touched any of the parameter, or done any tunning.\n",
    " - Some other models have really low scores (i.e QuadraticDiscriminantAnalysis, Perceptron...) : it means that maybe they need **much more data** in order to produce good results (Perceptron), or the model choosen is unable by definition to represent our data distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use grid search to optimize the models.  \n",
    "But first, we will select the models we want to keep, and for them, we will keep make a specific parameter grid according to what would potentially increase their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_algorithms_and_parameters = [\n",
    "        {\n",
    "            'model': ensemble.AdaBoostClassifier,\n",
    "            'param_grid': {\n",
    "                'algorithm': ['SAMME'],\n",
    "                'n_estimators': [50, 100],\n",
    "                'learning_rate': [0.01, 0.1, 0.3, 1]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': ensemble.BaggingClassifier,\n",
    "            'param_grid': {\n",
    "                'n_estimators': [10, 30, 90],\n",
    "                'max_features': [1, 2, 3]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': ensemble.ExtraTreesClassifier,\n",
    "            'param_grid': {\n",
    "                'n_estimators': [10, 30, 90],\n",
    "                'max_depth': [None, 3, 6],\n",
    "                'max_features': ['auto', 'log2', None]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': ensemble.GradientBoostingClassifier,\n",
    "            'param_grid': {\n",
    "                'learning_rate': [0.01, 0.1, 0.3, 1],\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [None, 3, 6]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': ensemble.RandomForestClassifier,\n",
    "            'param_grid': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [None, 3, 6],\n",
    "                'max_features': ['auto', 'log2', None]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': gaussian_process.GaussianProcessClassifier,\n",
    "            'param_grid': {\n",
    "                'max_iter_predict': [10, 30, 100, 300]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': linear_model.RidgeClassifierCV,\n",
    "            'param_grid': {\n",
    "                'alphas': [0.1, 0.3, 1.0, 3.0, 10.0]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': linear_model.SGDClassifier,\n",
    "            'param_grid': {\n",
    "                'loss': ['hinge', 'log', 'modified_huber'],\n",
    "                'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                'alpha': [0.0001, 0.001, 0.01, 0.1]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': naive_bayes.GaussianNB,\n",
    "            'param_grid': {\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': naive_bayes.BernoulliNB,\n",
    "            'param_grid': {\n",
    "                'alpha': [0.01, 0.1, 1.0]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': neighbors.KNeighborsClassifier,\n",
    "            'param_grid': {\n",
    "                'n_neighbors': [3, 5, 8]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': svm.SVC,\n",
    "            'param_grid': {\n",
    "                'C': [0.01, 0.1, 1],\n",
    "                'degree': [2, 3, 4, 5]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': svm.NuSVC,\n",
    "            'param_grid': {\n",
    "                'nu': [0.5, 0.7, 0.2],\n",
    "                'degree': [2, 3, 4, 5]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': svm.LinearSVC,\n",
    "            'param_grid': {\n",
    "                'penalty': ['l1'],\n",
    "                'C': [0.01, 0.1, 1],\n",
    "                'dual': [False]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': tree.DecisionTreeClassifier,\n",
    "            'param_grid': {\n",
    "                'splitter': ['random', 'best'],\n",
    "                'max_depth': [None, 3, 5, 10],\n",
    "                'max_features': ['auto', 'log2', None]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': tree.ExtraTreeClassifier,\n",
    "            'param_grid': {\n",
    "                'splitter': ['random', 'best'],\n",
    "                'max_depth': [None, 3, 5, 10],\n",
    "                'max_features': ['auto', 'log2', None]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model': discriminant_analysis.LinearDiscriminantAnalysis,\n",
    "            'param_grid': {\n",
    "                'solver': ['svd', 'lsqr'],\n",
    "            }\n",
    "        },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Model Parameters Tunned'] = ''\n",
    "results['Model Best Test F1 Score'] = pd.np.nan\n",
    "predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> AdaBoostClassifier\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                                          base_estimator=None,\n",
      "                                          learning_rate=1.0, n_estimators=50,\n",
      "                                          random_state=None),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'algorithm': ['SAMME'],\n",
      "                         'learning_rate': [0.01, 0.1, 0.3, 1],\n",
      "                         'n_estimators': [50, 100]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> BaggingClassifier\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "                                         bootstrap_features=False,\n",
      "                                         max_features=1.0, max_samples=1.0,\n",
      "                                         n_estimators=10, n_jobs=None,\n",
      "                                         oob_score=False, random_state=None,\n",
      "                                         verbose=0, warm_start=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'max_features': [1, 2, 3],\n",
      "                         'n_estimators': [10, 30, 90]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> ExtraTreesClassifier\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None,\n",
      "                                            criterion='gini', max_depth=None,\n",
      "                                            max_features='auto',\n",
      "                                            max_leaf_nodes=None,\n",
      "                                            min_impurity_decrease=0.0,\n",
      "                                            min_impurity_split=None,\n",
      "                                            min_samples_leaf=1,\n",
      "                                            min_samples_split=2,\n",
      "                                            min_weight_fraction_leaf=0.0,\n",
      "                                            n_estimators='warn', n_jobs=None,\n",
      "                                            oob_score=False, random_state=None,\n",
      "                                            verbose=0, warm_start=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'max_depth': [None, 3, 6],\n",
      "                         'max_features': ['auto', 'log2', None],\n",
      "                         'n_estimators': [10, 30, 90]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> GradientBoostingClassifier\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=GradientBoostingClassifier(criterion='friedman_mse',\n",
      "                                                  init=None, learning_rate=0.1,\n",
      "                                                  loss='deviance', max_depth=3,\n",
      "                                                  max_features=None,\n",
      "                                                  max_leaf_nodes=None,\n",
      "                                                  min_impurity_decrease=0.0,\n",
      "                                                  min_impurity_split=None,\n",
      "                                                  min_samples_leaf=1,\n",
      "                                                  min_samp...\n",
      "                                                  min_weight_fraction_leaf=0.0,\n",
      "                                                  n_estimators=100,\n",
      "                                                  n_iter_no_change=None,\n",
      "                                                  presort='auto',\n",
      "                                                  random_state=None,\n",
      "                                                  subsample=1.0, tol=0.0001,\n",
      "                                                  validation_fraction=0.1,\n",
      "                                                  verbose=0, warm_start=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'learning_rate': [0.01, 0.1, 0.3, 1],\n",
      "                         'max_depth': [None, 3, 6],\n",
      "                         'n_estimators': [100, 200]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> RandomForestClassifier\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                              criterion='gini', max_depth=None,\n",
      "                                              max_features='auto',\n",
      "                                              max_leaf_nodes=None,\n",
      "                                              min_impurity_decrease=0.0,\n",
      "                                              min_impurity_split=None,\n",
      "                                              min_samples_leaf=1,\n",
      "                                              min_samples_split=2,\n",
      "                                              min_weight_fraction_leaf=0.0,\n",
      "                                              n_estimators='warn', n_jobs=None,\n",
      "                                              oob_score=False,\n",
      "                                              random_state=None, verbose=0,\n",
      "                                              warm_start=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'max_depth': [None, 3, 6],\n",
      "                         'max_features': ['auto', 'log2', None],\n",
      "                         'n_estimators': [100, 200]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> GaussianProcessClassifier\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=GaussianProcessClassifier(copy_X_train=True, kernel=None,\n",
      "                                                 max_iter_predict=100,\n",
      "                                                 multi_class='one_vs_rest',\n",
      "                                                 n_jobs=None,\n",
      "                                                 n_restarts_optimizer=0,\n",
      "                                                 optimizer='fmin_l_bfgs_b',\n",
      "                                                 random_state=None,\n",
      "                                                 warm_start=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'max_iter_predict': [10, 30, 100, 300]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> RidgeClassifierCV\n",
      "len() of unsized object\n",
      "> SGDClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:530: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
      "                                     class_weight=None, early_stopping=False,\n",
      "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "                                     l1_ratio=0.15, learning_rate='optimal',\n",
      "                                     loss='hinge', max_iter=1000,\n",
      "                                     n_iter_no_change=5, n_jobs=None,\n",
      "                                     penalty='l2', power_t=0.5,\n",
      "                                     random_state=None, shuffle=True, tol=0.001,\n",
      "                                     validation_fraction=0.1, verbose=0,\n",
      "                                     warm_start=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
      "                         'loss': ['hinge', 'log', 'modified_huber'],\n",
      "                         'penalty': ['l2', 'l1', 'elasticnet']},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> GaussianNB\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=GaussianNB(priors=None, var_smoothing=1e-09), iid='warn',\n",
      "             n_jobs=None, param_grid={}, pre_dispatch='2*n_jobs', refit=True,\n",
      "             return_train_score=True, scoring='f1', verbose=0)\n",
      "> BernoulliNB\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None,\n",
      "                                   fit_prior=True),\n",
      "             iid='warn', n_jobs=None, param_grid={'alpha': [0.01, 0.1, 1.0]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> KNeighborsClassifier\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                            metric='minkowski',\n",
      "                                            metric_params=None, n_jobs=None,\n",
      "                                            n_neighbors=5, p=2,\n",
      "                                            weights='uniform'),\n",
      "             iid='warn', n_jobs=None, param_grid={'n_neighbors': [3, 5, 8]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                           decision_function_shape='ovr', degree=3,\n",
      "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
      "                           probability=False, random_state=None, shrinking=True,\n",
      "                           tol=0.001, verbose=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'C': [0.01, 0.1, 1], 'degree': [2, 3, 4, 5]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> NuSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "                             decision_function_shape='ovr', degree=3,\n",
      "                             gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
      "                             nu=0.5, probability=False, random_state=None,\n",
      "                             shrinking=True, tol=0.001, verbose=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'degree': [2, 3, 4, 5], 'nu': [0.5, 0.7, 0.2]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> LinearSVC\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                                 fit_intercept=True, intercept_scaling=1,\n",
      "                                 loss='squared_hinge', max_iter=1000,\n",
      "                                 multi_class='ovr', penalty='l2',\n",
      "                                 random_state=None, tol=0.0001, verbose=0),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'C': [0.01, 0.1, 1], 'dual': [False],\n",
      "                         'penalty': ['l1']},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> DecisionTreeClassifier\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                              criterion='gini', max_depth=None,\n",
      "                                              max_features=None,\n",
      "                                              max_leaf_nodes=None,\n",
      "                                              min_impurity_decrease=0.0,\n",
      "                                              min_impurity_split=None,\n",
      "                                              min_samples_leaf=1,\n",
      "                                              min_samples_split=2,\n",
      "                                              min_weight_fraction_leaf=0.0,\n",
      "                                              presort=False, random_state=None,\n",
      "                                              splitter='best'),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'max_depth': [None, 3, 5, 10],\n",
      "                         'max_features': ['auto', 'log2', None],\n",
      "                         'splitter': ['random', 'best']},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> ExtraTreeClassifier\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=ExtraTreeClassifier(class_weight=None, criterion='gini',\n",
      "                                           max_depth=None, max_features='auto',\n",
      "                                           max_leaf_nodes=None,\n",
      "                                           min_impurity_decrease=0.0,\n",
      "                                           min_impurity_split=None,\n",
      "                                           min_samples_leaf=1,\n",
      "                                           min_samples_split=2,\n",
      "                                           min_weight_fraction_leaf=0.0,\n",
      "                                           random_state=None,\n",
      "                                           splitter='random'),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'max_depth': [None, 3, 5, 10],\n",
      "                         'max_features': ['auto', 'log2', None],\n",
      "                         'splitter': ['random', 'best']},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n",
      "> LinearDiscriminantAnalysis\n",
      "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.2, train_size=0.8),\n",
      "             error_score='raise-deprecating',\n",
      "             estimator=LinearDiscriminantAnalysis(n_components=None,\n",
      "                                                  priors=None, shrinkage=None,\n",
      "                                                  solver='svd',\n",
      "                                                  store_covariance=False,\n",
      "                                                  tol=0.0001),\n",
      "             iid='warn', n_jobs=None, param_grid={'solver': ['svd', 'lsqr']},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='f1', verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "row_index = 0\n",
    "model_predictions = {}\n",
    "for model in ml_algorithms_and_parameters:\n",
    "    model_name = model['model']().__class__.__name__\n",
    "    print(f'> {model_name}')\n",
    "    params = model['param_grid'] if model['param_grid'] is not None else model.model.get_params()\n",
    "    \n",
    "    grid = GridSearchCV(model['model'](), param_grid=params, scoring='f1', cv=cv_split, return_train_score=True)\n",
    "    try:\n",
    "        cv_results = grid.fit(X, y)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    print(cv_results)\n",
    "    results.loc[results['Model Name'] == model_name, 'Model Parameters Tunned'] = str(cv_results.best_params_)\n",
    "    results.loc[results['Model Name'] == model_name, 'Model Best Test F1 Score'] = cv_results.best_score_ \n",
    "    cls = model['model'](**cv_results.best_params_).fit(X, y)\n",
    "    # predictions[model_name] = cls.predict(X_test)\n",
    "    predictions[model_name] = cls\n",
    "    row_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Parameters</th>\n",
       "      <th>Model Train F1 Score Mean</th>\n",
       "      <th>Model Test F1 Score Mean</th>\n",
       "      <th>Model Test F1 Score 3*STD</th>\n",
       "      <th>Model Time</th>\n",
       "      <th>Model Parameters Tunned</th>\n",
       "      <th>Model Best Test F1 Score</th>\n",
       "      <th>gain_by_tuning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>0.53418</td>\n",
       "      <td>0.51046</td>\n",
       "      <td>0.750526</td>\n",
       "      <td>0.00433413</td>\n",
       "      <td>{'alpha': 0.0001, 'loss': 'hinge', 'penalty': ...</td>\n",
       "      <td>0.762776</td>\n",
       "      <td>0.252315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'n_components': None, 'priors': None, 'shrink...</td>\n",
       "      <td>0.783491</td>\n",
       "      <td>0.75198</td>\n",
       "      <td>0.0889854</td>\n",
       "      <td>0.00699608</td>\n",
       "      <td>{'solver': 'svd'}</td>\n",
       "      <td>0.751980</td>\n",
       "      <td>1.11022e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'cri...</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.721341</td>\n",
       "      <td>0.0911531</td>\n",
       "      <td>0.122347</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>0.750566</td>\n",
       "      <td>0.0292252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.956077</td>\n",
       "      <td>0.725697</td>\n",
       "      <td>0.0916368</td>\n",
       "      <td>0.017988</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 30}</td>\n",
       "      <td>0.749542</td>\n",
       "      <td>0.023845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n",
       "      <td>0.875574</td>\n",
       "      <td>0.751254</td>\n",
       "      <td>0.069696</td>\n",
       "      <td>0.0796671</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.749326</td>\n",
       "      <td>-0.00192767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.579064</td>\n",
       "      <td>0.505241</td>\n",
       "      <td>0.400666</td>\n",
       "      <td>0.0353279</td>\n",
       "      <td>{'C': 1, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>0.745796</td>\n",
       "      <td>0.240555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'cr...</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.700279</td>\n",
       "      <td>0.152178</td>\n",
       "      <td>0.104001</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>0.745553</td>\n",
       "      <td>0.0452739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.641118</td>\n",
       "      <td>0.099632</td>\n",
       "      <td>0.0026656</td>\n",
       "      <td>{'max_depth': 5, 'max_features': None, 'splitt...</td>\n",
       "      <td>0.742455</td>\n",
       "      <td>0.101337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.801093</td>\n",
       "      <td>0.752075</td>\n",
       "      <td>0.0609638</td>\n",
       "      <td>0.0706893</td>\n",
       "      <td>{'algorithm': 'SAMME', 'learning_rate': 1, 'n_...</td>\n",
       "      <td>0.741353</td>\n",
       "      <td>-0.010722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.698069</td>\n",
       "      <td>0.0609913</td>\n",
       "      <td>0.00266631</td>\n",
       "      <td>{'max_depth': 5, 'max_features': None, 'splitt...</td>\n",
       "      <td>0.734859</td>\n",
       "      <td>0.0367897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>0.740125</td>\n",
       "      <td>0.712698</td>\n",
       "      <td>0.0992032</td>\n",
       "      <td>0.00266623</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.712698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.748321</td>\n",
       "      <td>0.702294</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.00266711</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.702294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'cache_size': 200, 'class_weight': None, 'coe...</td>\n",
       "      <td>0.88062</td>\n",
       "      <td>0.62482</td>\n",
       "      <td>0.135416</td>\n",
       "      <td>0.0906599</td>\n",
       "      <td>{'degree': 2, 'nu': 0.2}</td>\n",
       "      <td>0.629142</td>\n",
       "      <td>0.00432216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.749129</td>\n",
       "      <td>0.625394</td>\n",
       "      <td>0.0653938</td>\n",
       "      <td>0.0030009</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.625394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'cache_size': 200, 'class_weight': ...</td>\n",
       "      <td>0.851942</td>\n",
       "      <td>0.609723</td>\n",
       "      <td>0.0642592</td>\n",
       "      <td>0.0869946</td>\n",
       "      <td>{'C': 1, 'degree': 2}</td>\n",
       "      <td>0.609723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
       "      <td>0.941706</td>\n",
       "      <td>0.576224</td>\n",
       "      <td>0.026924</td>\n",
       "      <td>0.320696</td>\n",
       "      <td>{'max_iter_predict': 10}</td>\n",
       "      <td>0.576224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.748159</td>\n",
       "      <td>0.076795</td>\n",
       "      <td>0.00633303</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "      <td>0.424493</td>\n",
       "      <td>0.456111</td>\n",
       "      <td>0.722615</td>\n",
       "      <td>0.0036664</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
       "      <td>0.24482</td>\n",
       "      <td>0.207733</td>\n",
       "      <td>0.297017</td>\n",
       "      <td>0.00333095</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
       "      <td>0.0567638</td>\n",
       "      <td>0.0369634</td>\n",
       "      <td>0.0347295</td>\n",
       "      <td>0.00266616</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model Name  \\\n",
       "8                   SGDClassifier   \n",
       "18     LinearDiscriminantAnalysis   \n",
       "4          RandomForestClassifier   \n",
       "1               BaggingClassifier   \n",
       "3      GradientBoostingClassifier   \n",
       "15                      LinearSVC   \n",
       "2            ExtraTreesClassifier   \n",
       "17            ExtraTreeClassifier   \n",
       "0              AdaBoostClassifier   \n",
       "16         DecisionTreeClassifier   \n",
       "10                    BernoulliNB   \n",
       "11                     GaussianNB   \n",
       "14                          NuSVC   \n",
       "12           KNeighborsClassifier   \n",
       "13                            SVC   \n",
       "5       GaussianProcessClassifier   \n",
       "7               RidgeClassifierCV   \n",
       "9                      Perceptron   \n",
       "6     PassiveAggressiveClassifier   \n",
       "19  QuadraticDiscriminantAnalysis   \n",
       "\n",
       "                                     Model Parameters  \\\n",
       "8   {'alpha': 0.0001, 'average': False, 'class_wei...   \n",
       "18  {'n_components': None, 'priors': None, 'shrink...   \n",
       "4   {'bootstrap': True, 'class_weight': None, 'cri...   \n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...   \n",
       "3   {'criterion': 'friedman_mse', 'init': None, 'l...   \n",
       "15  {'C': 1.0, 'class_weight': None, 'dual': True,...   \n",
       "2   {'bootstrap': False, 'class_weight': None, 'cr...   \n",
       "17  {'class_weight': None, 'criterion': 'gini', 'm...   \n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...   \n",
       "16  {'class_weight': None, 'criterion': 'gini', 'm...   \n",
       "10  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...   \n",
       "11           {'priors': None, 'var_smoothing': 1e-09}   \n",
       "14  {'cache_size': 200, 'class_weight': None, 'coe...   \n",
       "12  {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "13  {'C': 1.0, 'cache_size': 200, 'class_weight': ...   \n",
       "5   {'copy_X_train': True, 'kernel': None, 'max_it...   \n",
       "7   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...   \n",
       "9   {'alpha': 0.0001, 'class_weight': None, 'early...   \n",
       "6   {'C': 1.0, 'average': False, 'class_weight': N...   \n",
       "19  {'priors': None, 'reg_param': 0.0, 'store_cova...   \n",
       "\n",
       "   Model Train F1 Score Mean Model Test F1 Score Mean  \\\n",
       "8                    0.53418                  0.51046   \n",
       "18                  0.783491                  0.75198   \n",
       "4                   0.983239                 0.721341   \n",
       "1                   0.956077                 0.725697   \n",
       "3                   0.875574                 0.751254   \n",
       "15                  0.579064                 0.505241   \n",
       "2                   0.983239                 0.700279   \n",
       "17                  0.983239                 0.641118   \n",
       "0                   0.801093                 0.752075   \n",
       "16                  0.983239                 0.698069   \n",
       "10                  0.740125                 0.712698   \n",
       "11                  0.748321                 0.702294   \n",
       "14                   0.88062                  0.62482   \n",
       "12                  0.749129                 0.625394   \n",
       "13                  0.851942                 0.609723   \n",
       "5                   0.941706                 0.576224   \n",
       "7                      0.787                 0.748159   \n",
       "9                   0.424493                 0.456111   \n",
       "6                    0.24482                 0.207733   \n",
       "19                 0.0567638                0.0369634   \n",
       "\n",
       "   Model Test F1 Score 3*STD  Model Time  \\\n",
       "8                   0.750526  0.00433413   \n",
       "18                 0.0889854  0.00699608   \n",
       "4                  0.0911531    0.122347   \n",
       "1                  0.0916368    0.017988   \n",
       "3                   0.069696   0.0796671   \n",
       "15                  0.400666   0.0353279   \n",
       "2                   0.152178    0.104001   \n",
       "17                  0.099632   0.0026656   \n",
       "0                  0.0609638   0.0706893   \n",
       "16                 0.0609913  0.00266631   \n",
       "10                 0.0992032  0.00266623   \n",
       "11                    0.1186  0.00266711   \n",
       "14                  0.135416   0.0906599   \n",
       "12                 0.0653938   0.0030009   \n",
       "13                 0.0642592   0.0869946   \n",
       "5                   0.026924    0.320696   \n",
       "7                   0.076795  0.00633303   \n",
       "9                   0.722615   0.0036664   \n",
       "6                   0.297017  0.00333095   \n",
       "19                 0.0347295  0.00266616   \n",
       "\n",
       "                              Model Parameters Tunned  \\\n",
       "8   {'alpha': 0.0001, 'loss': 'hinge', 'penalty': ...   \n",
       "18                                  {'solver': 'svd'}   \n",
       "4   {'max_depth': 3, 'max_features': 'log2', 'n_es...   \n",
       "1             {'max_features': 3, 'n_estimators': 30}   \n",
       "3   {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
       "15           {'C': 1, 'dual': False, 'penalty': 'l1'}   \n",
       "2   {'max_depth': 6, 'max_features': 'log2', 'n_es...   \n",
       "17  {'max_depth': 5, 'max_features': None, 'splitt...   \n",
       "0   {'algorithm': 'SAMME', 'learning_rate': 1, 'n_...   \n",
       "16  {'max_depth': 5, 'max_features': None, 'splitt...   \n",
       "10                                    {'alpha': 0.01}   \n",
       "11                                                 {}   \n",
       "14                           {'degree': 2, 'nu': 0.2}   \n",
       "12                                 {'n_neighbors': 5}   \n",
       "13                              {'C': 1, 'degree': 2}   \n",
       "5                            {'max_iter_predict': 10}   \n",
       "7                                                       \n",
       "9                                                       \n",
       "6                                                       \n",
       "19                                                      \n",
       "\n",
       "    Model Best Test F1 Score gain_by_tuning  \n",
       "8                   0.762776       0.252315  \n",
       "18                  0.751980    1.11022e-16  \n",
       "4                   0.750566      0.0292252  \n",
       "1                   0.749542       0.023845  \n",
       "3                   0.749326    -0.00192767  \n",
       "15                  0.745796       0.240555  \n",
       "2                   0.745553      0.0452739  \n",
       "17                  0.742455       0.101337  \n",
       "0                   0.741353      -0.010722  \n",
       "16                  0.734859      0.0367897  \n",
       "10                  0.712698              0  \n",
       "11                  0.702294              0  \n",
       "14                  0.629142     0.00432216  \n",
       "12                  0.625394              0  \n",
       "13                  0.609723              0  \n",
       "5                   0.576224              0  \n",
       "7                        NaN            NaN  \n",
       "9                        NaN            NaN  \n",
       "6                        NaN            NaN  \n",
       "19                       NaN            NaN  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['gain_by_tuning'] = results['Model Best Test F1 Score'] - results['Model Test F1 Score Mean']\n",
    "results.sort_values(by='Model Best Test F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on the results above, not every classifier gets better results from hyper parametrization.  \n",
    "In those cases, we will keep the previous model for our final ensembling model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we combine the classifier with a voting classifier.  \n",
    "In our current case, it is just on \"hard\" voting mode, which is \"it uses predicted class labels for majority rule voting\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_for_voting = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in predictions.items():\n",
    "    models_for_voting.append((model_name, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier = VotingClassifier(models_for_voting, voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thomas Coquereau\\Anaconda3\\envs\\epsilon\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "voting_classifier = voting_classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_predictions = voting_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([passenger_id, pd.Series(voting_predictions)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.rename({0: 'Survived'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('submission_voting.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to this submission with the voting classifier, I was able to jump 10,721 places on Kaggle's leaderboard from my previous submission with just a RandomForestClassifier.  \n",
    "Scoring 0.78947 instead of the previous 0.73205.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much more could be done about this classification problem, but we are gonna continue exploring various datasets and hopefully learn more about Data Science on the way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
